
# Task 2: Fine-tuning TTS for a Regional Language

## Dataset Description

Two different dataset are  used for training  one is Bengali_Competition_Dataset available on the Hugging Face Hub.
[![Hugging Face Datasets](https://img.shields.io/badge/Hugging%20Face%20Datasets-464646?style=for-the-badge&logo=huggingface&logoColor=white)](https://huggingface.co/datasets/spygaurad/Bengali_Competition_Dataset)

It contains approximately 629,442 spoken Bengali sentences. For this experiment, only 10,490 samples were used due to processing and time limitations.

You can find the colab notebbok from the bellow Links.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1g5kfw7dHK8KMdgbnUIeXXjwWuviXitB_?usp=sharing)

and another dataset is Bengali_AI_Speech

[![Hugging Face Datasets](https://img.shields.io/badge/Hugging%20Face%20Datasets-464646?style=for-the-badge&logo=huggingface&logoColor=white)](https://huggingface.co/datasets/arif11/Bengali_AI_Speech)

It contains approximately 32762 spoken Bengali sentences. For this experiment, only 16381 samples were used due to processing and time limitations.

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pratim808/TTS_Bengali/blob/main/Copy_of_Fine_Tune_SpeechT5.ipynb)




## Notes

Despite training the model on two datasets for 5,000 steps, the model is not generating speech output for the given text.

You can find the colab notebbok and the github repository from the bellow Links.




